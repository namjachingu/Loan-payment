{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import random\n",
    "random.seed(101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"lending_club_loan_two.csv\")\n",
    "\n",
    "df.info()\n",
    "\n",
    "sns.countplot(x=\"loan_status\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,2))\n",
    "sns.displot(x=\"loan_amnt\", data=df, kde=False, bins=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of correlation between continuous feature variables\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.heatmap(df.corr(),annot=True,cmap=\"plasma\")\n",
    "plt.ylim(10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between installment and loan amount as a scatterplot.\n",
    "sns.scatterplot(x=\"installment\", y=\"loan_amnt\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot illustrating the relationship between loan status and loan amount.\n",
    "sns.boxplot(x=\"loan_status\", y=\"loan_amnt\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the summary statistics for the loan amount, grouped by loan status.\n",
    "df.groupby('loan_status')['loan_amnt'].describe()\n",
    "\n",
    "#Countplot per grade\n",
    "sns.countplot(sorted(df[\"grade\"]), data=df, hue=\"loan_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display countplot of subgrades, by all loans and then separated based on loan status.\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.countplot(x=sorted(df['sub_grade']), data=df, palette=\"summer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "sns.countplot(x=sorted(df['sub_grade']), data=df, hue=\"loan_status\", palette=\"summer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[(df['grade'] == \"F\") | (df['grade'] == \"G\")]\n",
    "\n",
    "#F and G subgrades do not pay back that often, hence exploring those features:\n",
    "plt.figure(figsize=(20,12))\n",
    "sub_order = sorted(df_2[\"sub_grade\"].unique())\n",
    "sns.countplot(x=\"sub_grade\", data=df_2, order=sub_order, hue=\"loan_status\", palette=\"summer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding new column, loan repaid, where if loan status is fully repaid it will return 1 and 0 otherwise. \n",
    "def repaid(status):\n",
    "    if status.lower() == \"fully paid\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    " \n",
    "df[\"loan_repaid\"] = df[\"loan_status\"].apply(repaid)\n",
    "df[[\"loan_status\", \"loan_repaid\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data preprocessing ###\n",
    "missing_val = df.isnull().sum()\n",
    "missing_val_percentage = (100*df.isnull().sum())/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"emp_title\"].nunique()\n",
    "df[ \"emp_length\"].nunique()\n",
    "\n",
    "df.drop(\"emp_title\", axis=1, inplace=True)\n",
    "\n",
    "sorted(df['emp_length'].dropna().unique())\n",
    "sorted_emp = ['< 1 year', '1 year','2 years','3 years','4 years','5 years','6 years','7 years','8 years','9 years','10+ years']\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.countplot(x=\"emp_length\", data=df, order=sorted_emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "sns.countplot(x=\"emp_length\", data=df, order=sorted_emp, hue=\"loan_status\", palette=\"winter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking in percentage how many people did not pay back their loan with regards to employment years.\n",
    "charged_off = df[df['loan_status'] == \"Charged Off\"].groupby(\"emp_length\").count()['loan_status']\n",
    "fully_paid = df[df['loan_status'] == \"Fully Paid\"].groupby(\"emp_length\").count()['loan_status']\n",
    "employment_length = charged_off/fully_paid\n",
    "\n",
    "df.drop([\"emp_length\", \"title\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in empty slots with mean of total number of credit lines currrently in the borrower's credit file\n",
    "df[\"mort_acc\"].value_counts()\n",
    "acc_avg = df.groupby(\"total_acc\").mean()[\"mort_acc\"]\n",
    "\n",
    "def fill_na(total_acc,mort_acc):\n",
    "    if np.isnan(mort_acc):\n",
    "        return acc_avg[total_acc]\n",
    "    else:\n",
    "        return mort_acc\n",
    "\n",
    "df['mort_acc'] = df.apply(lambda x: fill_na(x['total_acc'], x['mort_acc']), axis=1)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert objects to integers\n",
    "def converter(term):\n",
    "    term = term.split()\n",
    "    if term[0] == \"36\":\n",
    "        return 36\n",
    "    else:\n",
    "        return 60\n",
    "    \n",
    "df[\"term\"] = df[\"term\"].apply(converter)\n",
    "\n",
    "df.drop([\"grade\", \"issue_d\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_int = pd.get_dummies(df[['sub_grade', 'verification_status', 'application_type','initial_list_status','purpose' ]],drop_first=True)\n",
    "df = df.drop(['sub_grade', 'verification_status', 'application_type','initial_list_status','purpose'],axis=1)\n",
    "df = pd.concat([df,features_int],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and replace object values\n",
    "df['home_ownership'] = df['home_ownership'].replace(['NONE', 'ANY'], 'OTHER')\n",
    "home_ownership_int = pd.get_dummies(df[\"home_ownership\"], drop_first=True)\n",
    "df = df.drop('home_ownership',axis=1)\n",
    "df = pd.concat([df, home_ownership_int],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating zip column from address\n",
    "def zip_extract(address):\n",
    "    zip = address.split()[-1]\n",
    "    return zip\n",
    "\n",
    "df[\"zip_code\"] = df[\"address\"].apply(zip_extract)\n",
    "\n",
    "zip_code_int = pd.get_dummies(df[\"zip_code\"], drop_first=True)\n",
    "df.drop([\"zip_code\", \"address\"], axis=1, inplace=True)\n",
    "df = pd.concat([df, zip_code_int], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertInt(time):\n",
    "    time = time.split(\"-\")\n",
    "    year = int(time[1])\n",
    "    return year\n",
    "\n",
    "df[\"earliest_cr_line\"] = df[\"earliest_cr_line\"].apply(convertInt)\n",
    "\n",
    "df.drop(\"loan_status\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train test split ###\n",
    "\n",
    "X = df.drop('loan_repaid',axis=1).values\n",
    "y = df['loan_repaid'].values\n",
    "\n",
    "# Grabbing a fraction of the entries to save time and compute on training.\n",
    "df = df.sample(frac=0.1,random_state=101)\n",
    "print(len(df))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating model ### \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=78,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=39,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=19,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "model.fit(x=X_train, y=y_train, epochs=25, batch_size=256, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save model\n",
    "model.save('loan_model.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate performance of model ###\n",
    "losses = pd.DataFrame(model.history.history)\n",
    "losses[['loss','val_loss']].plot()\n",
    "\n",
    "predictions = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "confusion_matrix(y_test, predictions)\n",
    "classification_report(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on new costumer\n",
    "random_index = random.randint(0,len(df))\n",
    "new_customer = df.drop('loan_repaid',axis=1).iloc[random_index]\n",
    "new_customer = scaler.transform(new_customer.values.reshape(1,78))\n",
    "(model.predict(new_customer) > 0.5).astype(\"int32\")\n",
    "df.iloc[random_index][\"loan_repaid\"]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
